{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA_Bot.ipynb",
      "provenance": [],
      "mount_file_id": "1GF1FaIyZQuBemmoH305hq2daEGbFHmCI",
      "authorship_tag": "ABX9TyMD+ccN0maC/9+qEoeGIWIk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ztUsOZtxC4",
        "colab_type": "text"
      },
      "source": [
        "# Question Answer ChatBot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUsrjrM5t78j",
        "colab_type": "text"
      },
      "source": [
        "## 1) Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU1QksIAts3T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1190f0e7-3e11-4e7f-cbd4-69d8fbac61be"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnp_rB1duGwb",
        "colab_type": "text"
      },
      "source": [
        "## 2) Reading data from file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYlwo1eruFkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For training\n",
        "\n",
        "with open('drive/My Drive/Pytorch_DataSet/Ghost_Writer/train_qa_one.txt','rb') as f:\n",
        "  train_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk7uqXwzub5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For testing\n",
        "\n",
        "with open('/content/drive/My Drive/Pytorch_DataSet/Ghost_Writer/test_qa_one.txt','rb') as f:\n",
        "  test_data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWH8ujECukc-",
        "colab_type": "code",
        "outputId": "da3386d8-9da0-45fc-e751-353bd992ec3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data), len(test_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNL7DzIVq3qk",
        "colab_type": "code",
        "outputId": "72b7bee7-63f8-43d4-8e9a-2a908594ba04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-TNws4TunrS",
        "colab_type": "code",
        "outputId": "41271693-9119-4663-d43a-429fd902b471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['the',\n",
              "  'coming',\n",
              "  'of',\n",
              "  'the',\n",
              "  'martians',\n",
              "  'no',\n",
              "  'one',\n",
              "  'would',\n",
              "  'have',\n",
              "  'believed',\n",
              "  'in',\n",
              "  'the',\n",
              "  'last',\n",
              "  'years',\n",
              "  'of',\n",
              "  'the',\n",
              "  'nineteenth',\n",
              "  'century',\n",
              "  'that',\n",
              "  'this',\n",
              "  'world',\n",
              "  'was',\n",
              "  'being',\n",
              "  'watched',\n",
              "  'by',\n",
              "  'martians',\n",
              "  'and',\n",
              "  'yet',\n",
              "  'as',\n",
              "  'mortal',\n",
              "  'as',\n",
              "  'his',\n",
              "  'own',\n",
              "  ';',\n",
              "  'that',\n",
              "  'as',\n",
              "  'men',\n",
              "  'busied',\n",
              "  'themselves',\n",
              "  'about',\n",
              "  'their',\n",
              "  'various',\n",
              "  'concerns',\n",
              "  'they',\n",
              "  'were',\n",
              "  'scrutinised',\n",
              "  'and',\n",
              "  'studied',\n",
              "  ',',\n",
              "  'perhaps',\n",
              "  'almost',\n",
              "  'as',\n",
              "  'narrowly',\n",
              "  'as',\n",
              "  'a',\n",
              "  'man',\n",
              "  'with',\n",
              "  'a',\n",
              "  'microscope',\n",
              "  'might',\n",
              "  'scrutinise',\n",
              "  'the',\n",
              "  'transient',\n",
              "  'creatures',\n",
              "  'that',\n",
              "  'swarm',\n",
              "  'and',\n",
              "  'multiply',\n",
              "  'in',\n",
              "  'a',\n",
              "  'drop',\n",
              "  'of',\n",
              "  'water',\n",
              "  '.'],\n",
              " ['was', 'world', 'being', 'watched', 'by', 'martians', '?'],\n",
              " 'yes')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj44BytWtuCh",
        "colab_type": "code",
        "outputId": "38c5884a-6f1d-44db-f8da-f772f2bd1cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(train_data[1][0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'and we men , the creatures who inhabit this earth , must be to them at least as alien and humans are as lowly to martians as are the monkeys to humans . the intellectual side of man already admits that life is an incessant struggle for existence , and it would seem that this too is the belief of the minds upon mars . that , generation after generation , creeps upon them .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtQvroip1goT",
        "colab_type": "code",
        "outputId": "3f9dc244-6728-4fbd-b16a-cf3edf033a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yARv8Fnvu3e4",
        "colab_type": "code",
        "outputId": "b67bbd4c-c139-4f65-9b1e-01f1fe826a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the coming of the martians no one would have believed in the last years of the nineteenth century that this world was being watched by martians and yet as mortal as his own ; that as men busied themselves about their various concerns they were scrutinised and studied , perhaps almost as narrowly as a man with a microscope might scrutinise the transient creatures that swarm and multiply in a drop of water .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9eL3Iq4TVac",
        "colab_type": "code",
        "outputId": "70fb4f14-8f22-470c-9190-025c2104e460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "print(train_data[1][0])\n",
        "a = iter(train_data)\n",
        "while next(a):\n",
        "  b = next(a)\n",
        "  print((b[0]))\n",
        "\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(train_data[1][0])\\na = iter(train_data)\\nwhile next(a):\\n  b = next(a)\\n  print((b[0]))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1tVMHKKvDaB",
        "colab_type": "code",
        "outputId": "67e90b73-bdac-4c7b-e80c-1e09f2b525d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'was world being watched by martians ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1WkErkpvQq7",
        "colab_type": "code",
        "outputId": "88469afd-d897-4ef2-f593-09b4ab53b629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "''.join(train_data[0][2])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmnTrFlgvT_c",
        "colab_type": "code",
        "outputId": "d97100de-278a-4d18-be62-4b3c8bb7daf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data), type(test_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRLLcWE6wK0Y",
        "colab_type": "text"
      },
      "source": [
        "## 3) Creating a dictionary.\n",
        "\n",
        "Creating a dictionary that contains all the words our train and test set has got so that the test data do not contain any word which is not present in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fNwT-RzvgKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = train_data + test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dolfQs4wwjx6",
        "colab_type": "code",
        "outputId": "86f89db4-509d-4270-8c32-2d0ba8f9547e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(all_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqBF5UTBxi47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "\n",
        "for statement,query, answer in all_data:\n",
        "  vocab = vocab.union(set(statement))\n",
        "  vocab = vocab.union(set(query))\n",
        "\n",
        "vocab.add('no')\n",
        "vocab.add('yes')  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wucVP9iQyBi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f8dLk9VyC2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding the pad sequences in case if the string is too short or too long\n",
        "vocab_len = len(vocab) + 1 # 1 for padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vUGGGYhyg-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, checking the length of the longest story that can be used in padding\n",
        "\n",
        "#Longest story\n",
        "\n",
        "all_story_len = [len(data[0]) for data in all_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZItciCw4zOcA",
        "colab_type": "code",
        "outputId": "5ed71295-711b-40c9-c423-344b18e87796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_story_len[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[74, 75, 63, 64, 66, 50, 66, 60, 83, 60]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIEkIiOXzPgV",
        "colab_type": "code",
        "outputId": "905e5d6d-0778-4ddb-9753-1f9cf195bf5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_story_len = max(all_story_len)\n",
        "max_story_len"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPXKbWjfzYQK",
        "colab_type": "code",
        "outputId": "06cd0c25-ad2f-48fd-afb8-f41cd04b69b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_question_len = [len(data[1]) for data in all_data]\n",
        "all_question_len[:10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 12, 7, 6, 11, 10, 7, 7, 9, 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdHIVIGYFeDU",
        "colab_type": "code",
        "outputId": "46b4a204-d1cb-4bb9-fe8d-5ba313977ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_question_len = max(all_question_len)\n",
        "max_question_len"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGKhXnKfitXn",
        "colab_type": "text"
      },
      "source": [
        "## 4) Vectorizing the Data\n",
        "\n",
        "Conversion of text into numerical values\n",
        "\n",
        "https://stackoverflow.com/questions/42943291/what-does-keras-io-preprocessing-sequence-pad-sequences-do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgDUNkVyFqAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_il-qPHfjD3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBDB72LdjoQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-ckqMeojvKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separating the story, question and answer from the training set\n",
        "\n",
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answer_text = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "  train_story_text.append(story)\n",
        "  train_question_text.append(question)\n",
        "  train_answer_text.append(answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzEwzz-elrQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_story_text[:1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sLmQokls_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the story , question and answer in numerical form\n",
        "\n",
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G_xGpMPnG0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_story_seq[:1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0aM8MQinIjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        " \n",
        "  # X = STORIES\n",
        "  X = []\n",
        "  # Xq = QUERY/QUESTION\n",
        "  Xq = []\n",
        "  # Y = CORRECT ANSWER\n",
        "  Y = []\n",
        "  \n",
        "  \n",
        "  for story, query, answer in data:\n",
        "      \n",
        "    x = [word_index[word.lower()] for word in story]\n",
        "    xq = [word_index[word.lower()] for word in query]\n",
        "\n",
        "    # Index 0 is reserved so we're going to use + 1\n",
        "    y = np.zeros(len(word_index) + 1)\n",
        "    \n",
        "    \n",
        "    y[word_index[answer]] = 1\n",
        "    \n",
        "    X.append(x)\n",
        "    Xq.append(xq)\n",
        "    Y.append(y)\n",
        "      \n",
        "  # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "      \n",
        "  return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3ORx454yH58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Qbq2hSyLEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcke-ta2yNjD",
        "colab_type": "code",
        "outputId": "3da79313-204e-4f57-e9bd-229795fbf58e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "inputs_train"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,  943,  739,  404],\n",
              "       [   0,    0,    0, ...,  555,  381,  404],\n",
              "       [   0,    0,    0, ...,  804,  743, 1054],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  886, 1389,  404],\n",
              "       [   0,    0,    0, ...,  289,  923,  404],\n",
              "       [   0,    0,    0, ...,  360,  442,  404]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMc_KeZcyWEh",
        "colab_type": "code",
        "outputId": "08797d5f-0ce0-4ccf-e2d0-41ada57010e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "inputs_test"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   97, 1296,  404],\n",
              "       [   0,    0,    0, ...,  769,  189,  404],\n",
              "       [   0,    0,    0, ..., 1252,  343,  404],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  886, 1389,  404],\n",
              "       [   0,    0,    0, ...,  289,  923,  404],\n",
              "       [   0,    0,    0, ...,  360,  442,  404]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou85hftJyZTT",
        "colab_type": "code",
        "outputId": "2cbabd0f-a986-4392-a78a-67ea68a22a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "answers_test"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvdg3AGzK5zu",
        "colab_type": "text"
      },
      "source": [
        "## 5) Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1RM4RWRycqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAsGotd4K_tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We have two inputs, stories and questions. So we need to use placeholders. Input() is used to instantiate a Keras tensor.\n",
        "# PlaceHolder shape = (max_story_len,batch_size)\n",
        "\n",
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))\n",
        "\n",
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JTOViNpOmiC",
        "colab_type": "text"
      },
      "source": [
        "Input Encoder m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUnHQXaXMDBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeJAU9LDOq8T",
        "colab_type": "text"
      },
      "source": [
        "Input Encoder c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaGsssBROQHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U5o1QlwOzZe",
        "colab_type": "text"
      },
      "source": [
        "Question Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE-zF4Y1OcTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,output_dim=64,input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVzYWX-pRHlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "\n",
        "# ENCODED <---- ENCODER (INPUT)\n",
        "\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRbw6Z8qRJYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxadf04bS3xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkPmWuGhS6iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfzstpYBS9Vy",
        "colab_type": "code",
        "outputId": "3c1d245d-23b8-4707-e079-894f12f459bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answer"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'concatenate_1/concat:0' shape=(None, 14, 183) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjdm2ZlaTQht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsADqRvFTUx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seq0720uTYLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGLZFRWDTpu_",
        "colab_type": "code",
        "outputId": "1af7e118-1665-4f84-82cf-9add376ebc24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 119)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 14)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       multiple             95168       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 14, 64)       95168       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 119, 14)      0           sequential_1[1][0]               \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 119, 14)      0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       multiple             20818       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 119, 14)      0           activation_1[0][0]               \n",
            "                                                                 sequential_2[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 14, 119)      0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 14, 183)      0           permute_1[0][0]                  \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           27648       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1487)         49071       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1487)         0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 287,873\n",
            "Trainable params: 287,873\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8tZzpKIXBkh",
        "colab_type": "text"
      },
      "source": [
        "## 6) Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9ZgrHLNTvwS",
        "colab_type": "code",
        "outputId": "2bd00869-2cf3-44f4-ab2d-bf0effe69418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=150)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "112/112 [==============================] - 1s 5ms/step - loss: 7.2441 - accuracy: 0.1607\n",
            "Epoch 2/150\n",
            "112/112 [==============================] - 0s 750us/step - loss: 6.9470 - accuracy: 0.5179\n",
            "Epoch 3/150\n",
            "112/112 [==============================] - 0s 750us/step - loss: 6.3741 - accuracy: 0.5536\n",
            "Epoch 4/150\n",
            "112/112 [==============================] - 0s 792us/step - loss: 5.8956 - accuracy: 0.5446\n",
            "Epoch 5/150\n",
            "112/112 [==============================] - 0s 794us/step - loss: 5.4635 - accuracy: 0.5446\n",
            "Epoch 6/150\n",
            "112/112 [==============================] - 0s 770us/step - loss: 5.0416 - accuracy: 0.5804\n",
            "Epoch 7/150\n",
            "112/112 [==============================] - 0s 758us/step - loss: 4.7108 - accuracy: 0.5536\n",
            "Epoch 8/150\n",
            "112/112 [==============================] - 0s 735us/step - loss: 4.3424 - accuracy: 0.5893\n",
            "Epoch 9/150\n",
            "112/112 [==============================] - 0s 793us/step - loss: 4.1595 - accuracy: 0.5893\n",
            "Epoch 10/150\n",
            "112/112 [==============================] - 0s 788us/step - loss: 3.7705 - accuracy: 0.6071\n",
            "Epoch 11/150\n",
            "112/112 [==============================] - 0s 736us/step - loss: 3.4863 - accuracy: 0.5357\n",
            "Epoch 12/150\n",
            "112/112 [==============================] - 0s 699us/step - loss: 3.2568 - accuracy: 0.5089\n",
            "Epoch 13/150\n",
            "112/112 [==============================] - 0s 701us/step - loss: 2.8575 - accuracy: 0.5714\n",
            "Epoch 14/150\n",
            "112/112 [==============================] - 0s 735us/step - loss: 2.6242 - accuracy: 0.5804\n",
            "Epoch 15/150\n",
            "112/112 [==============================] - 0s 696us/step - loss: 2.4945 - accuracy: 0.5268\n",
            "Epoch 16/150\n",
            "112/112 [==============================] - 0s 716us/step - loss: 2.2781 - accuracy: 0.5536\n",
            "Epoch 17/150\n",
            "112/112 [==============================] - 0s 729us/step - loss: 2.1159 - accuracy: 0.6429\n",
            "Epoch 18/150\n",
            "112/112 [==============================] - 0s 739us/step - loss: 1.8198 - accuracy: 0.6161\n",
            "Epoch 19/150\n",
            "112/112 [==============================] - 0s 856us/step - loss: 1.9848 - accuracy: 0.4643\n",
            "Epoch 20/150\n",
            "112/112 [==============================] - 0s 739us/step - loss: 1.7653 - accuracy: 0.5089\n",
            "Epoch 21/150\n",
            "112/112 [==============================] - 0s 840us/step - loss: 1.5325 - accuracy: 0.6071\n",
            "Epoch 22/150\n",
            "112/112 [==============================] - 0s 727us/step - loss: 1.5680 - accuracy: 0.5714\n",
            "Epoch 23/150\n",
            "112/112 [==============================] - 0s 749us/step - loss: 1.3863 - accuracy: 0.5536\n",
            "Epoch 24/150\n",
            "112/112 [==============================] - 0s 744us/step - loss: 1.3369 - accuracy: 0.5714\n",
            "Epoch 25/150\n",
            "112/112 [==============================] - 0s 716us/step - loss: 1.2965 - accuracy: 0.5893\n",
            "Epoch 26/150\n",
            "112/112 [==============================] - 0s 706us/step - loss: 1.1653 - accuracy: 0.6161\n",
            "Epoch 27/150\n",
            "112/112 [==============================] - 0s 720us/step - loss: 1.1010 - accuracy: 0.5982\n",
            "Epoch 28/150\n",
            "112/112 [==============================] - 0s 713us/step - loss: 1.0894 - accuracy: 0.5982\n",
            "Epoch 29/150\n",
            "112/112 [==============================] - 0s 818us/step - loss: 1.0041 - accuracy: 0.5536\n",
            "Epoch 30/150\n",
            "112/112 [==============================] - 0s 735us/step - loss: 1.0431 - accuracy: 0.5625\n",
            "Epoch 31/150\n",
            "112/112 [==============================] - 0s 742us/step - loss: 1.0892 - accuracy: 0.5179\n",
            "Epoch 32/150\n",
            "112/112 [==============================] - 0s 726us/step - loss: 0.9414 - accuracy: 0.5893\n",
            "Epoch 33/150\n",
            "112/112 [==============================] - 0s 817us/step - loss: 0.8999 - accuracy: 0.5446\n",
            "Epoch 34/150\n",
            "112/112 [==============================] - 0s 798us/step - loss: 0.8993 - accuracy: 0.5893\n",
            "Epoch 35/150\n",
            "112/112 [==============================] - 0s 743us/step - loss: 0.8415 - accuracy: 0.5357\n",
            "Epoch 36/150\n",
            "112/112 [==============================] - 0s 721us/step - loss: 0.8509 - accuracy: 0.6429\n",
            "Epoch 37/150\n",
            "112/112 [==============================] - 0s 711us/step - loss: 0.8494 - accuracy: 0.5625\n",
            "Epoch 38/150\n",
            "112/112 [==============================] - 0s 702us/step - loss: 0.8279 - accuracy: 0.5804\n",
            "Epoch 39/150\n",
            "112/112 [==============================] - 0s 782us/step - loss: 0.8263 - accuracy: 0.6250\n",
            "Epoch 40/150\n",
            "112/112 [==============================] - 0s 739us/step - loss: 0.8456 - accuracy: 0.5893\n",
            "Epoch 41/150\n",
            "112/112 [==============================] - 0s 774us/step - loss: 0.8400 - accuracy: 0.5625\n",
            "Epoch 42/150\n",
            "112/112 [==============================] - 0s 734us/step - loss: 0.7989 - accuracy: 0.5804\n",
            "Epoch 43/150\n",
            "112/112 [==============================] - 0s 727us/step - loss: 0.7869 - accuracy: 0.5536\n",
            "Epoch 44/150\n",
            "112/112 [==============================] - 0s 733us/step - loss: 0.7495 - accuracy: 0.5625\n",
            "Epoch 45/150\n",
            "112/112 [==============================] - 0s 768us/step - loss: 0.7694 - accuracy: 0.5536\n",
            "Epoch 46/150\n",
            "112/112 [==============================] - 0s 697us/step - loss: 0.7838 - accuracy: 0.5893\n",
            "Epoch 47/150\n",
            "112/112 [==============================] - 0s 706us/step - loss: 0.7596 - accuracy: 0.5536\n",
            "Epoch 48/150\n",
            "112/112 [==============================] - 0s 728us/step - loss: 0.7260 - accuracy: 0.5804\n",
            "Epoch 49/150\n",
            "112/112 [==============================] - 0s 714us/step - loss: 0.7550 - accuracy: 0.5804\n",
            "Epoch 50/150\n",
            "112/112 [==============================] - 0s 709us/step - loss: 0.7196 - accuracy: 0.6071\n",
            "Epoch 51/150\n",
            "112/112 [==============================] - 0s 699us/step - loss: 0.7461 - accuracy: 0.6071\n",
            "Epoch 52/150\n",
            "112/112 [==============================] - 0s 704us/step - loss: 0.7302 - accuracy: 0.5804\n",
            "Epoch 53/150\n",
            "112/112 [==============================] - 0s 732us/step - loss: 0.7427 - accuracy: 0.5714\n",
            "Epoch 54/150\n",
            "112/112 [==============================] - 0s 737us/step - loss: 0.7592 - accuracy: 0.5893\n",
            "Epoch 55/150\n",
            "112/112 [==============================] - 0s 707us/step - loss: 0.7553 - accuracy: 0.5446\n",
            "Epoch 56/150\n",
            "112/112 [==============================] - 0s 715us/step - loss: 0.7371 - accuracy: 0.5982\n",
            "Epoch 57/150\n",
            "112/112 [==============================] - 0s 781us/step - loss: 0.7157 - accuracy: 0.5804\n",
            "Epoch 58/150\n",
            "112/112 [==============================] - 0s 728us/step - loss: 0.7012 - accuracy: 0.5804\n",
            "Epoch 59/150\n",
            "112/112 [==============================] - 0s 727us/step - loss: 0.6989 - accuracy: 0.5982\n",
            "Epoch 60/150\n",
            "112/112 [==============================] - 0s 706us/step - loss: 0.7110 - accuracy: 0.5446\n",
            "Epoch 61/150\n",
            "112/112 [==============================] - 0s 707us/step - loss: 0.7197 - accuracy: 0.5714\n",
            "Epoch 62/150\n",
            "112/112 [==============================] - 0s 700us/step - loss: 0.7139 - accuracy: 0.5982\n",
            "Epoch 63/150\n",
            "112/112 [==============================] - 0s 711us/step - loss: 0.7059 - accuracy: 0.5625\n",
            "Epoch 64/150\n",
            "112/112 [==============================] - 0s 950us/step - loss: 0.7132 - accuracy: 0.5804\n",
            "Epoch 65/150\n",
            "112/112 [==============================] - 0s 765us/step - loss: 0.7199 - accuracy: 0.5714\n",
            "Epoch 66/150\n",
            "112/112 [==============================] - 0s 749us/step - loss: 0.7046 - accuracy: 0.5893\n",
            "Epoch 67/150\n",
            "112/112 [==============================] - 0s 780us/step - loss: 0.7005 - accuracy: 0.5982\n",
            "Epoch 68/150\n",
            "112/112 [==============================] - 0s 717us/step - loss: 0.7110 - accuracy: 0.5893\n",
            "Epoch 69/150\n",
            "112/112 [==============================] - 0s 818us/step - loss: 0.6900 - accuracy: 0.6071\n",
            "Epoch 70/150\n",
            "112/112 [==============================] - 0s 753us/step - loss: 0.6944 - accuracy: 0.5893\n",
            "Epoch 71/150\n",
            "112/112 [==============================] - 0s 722us/step - loss: 0.6867 - accuracy: 0.5893\n",
            "Epoch 72/150\n",
            "112/112 [==============================] - 0s 720us/step - loss: 0.7106 - accuracy: 0.5982\n",
            "Epoch 73/150\n",
            "112/112 [==============================] - 0s 694us/step - loss: 0.6947 - accuracy: 0.5804\n",
            "Epoch 74/150\n",
            "112/112 [==============================] - 0s 698us/step - loss: 0.7001 - accuracy: 0.5893\n",
            "Epoch 75/150\n",
            "112/112 [==============================] - 0s 702us/step - loss: 0.6940 - accuracy: 0.5982\n",
            "Epoch 76/150\n",
            "112/112 [==============================] - 0s 699us/step - loss: 0.6885 - accuracy: 0.5893\n",
            "Epoch 77/150\n",
            "112/112 [==============================] - 0s 705us/step - loss: 0.6824 - accuracy: 0.6071\n",
            "Epoch 78/150\n",
            "112/112 [==============================] - 0s 758us/step - loss: 0.6878 - accuracy: 0.5982\n",
            "Epoch 79/150\n",
            "112/112 [==============================] - 0s 715us/step - loss: 0.6964 - accuracy: 0.5804\n",
            "Epoch 80/150\n",
            "112/112 [==============================] - 0s 774us/step - loss: 0.6973 - accuracy: 0.5982\n",
            "Epoch 81/150\n",
            "112/112 [==============================] - 0s 828us/step - loss: 0.6824 - accuracy: 0.5982\n",
            "Epoch 82/150\n",
            "112/112 [==============================] - 0s 827us/step - loss: 0.6899 - accuracy: 0.5893\n",
            "Epoch 83/150\n",
            "112/112 [==============================] - 0s 801us/step - loss: 0.6792 - accuracy: 0.6071\n",
            "Epoch 84/150\n",
            "112/112 [==============================] - 0s 778us/step - loss: 0.6591 - accuracy: 0.6071\n",
            "Epoch 85/150\n",
            "112/112 [==============================] - 0s 788us/step - loss: 0.7042 - accuracy: 0.5893\n",
            "Epoch 86/150\n",
            "112/112 [==============================] - 0s 783us/step - loss: 0.6897 - accuracy: 0.6071\n",
            "Epoch 87/150\n",
            "112/112 [==============================] - 0s 913us/step - loss: 0.6856 - accuracy: 0.5982\n",
            "Epoch 88/150\n",
            "112/112 [==============================] - 0s 719us/step - loss: 0.6787 - accuracy: 0.6071\n",
            "Epoch 89/150\n",
            "112/112 [==============================] - 0s 730us/step - loss: 0.6917 - accuracy: 0.5893\n",
            "Epoch 90/150\n",
            "112/112 [==============================] - 0s 719us/step - loss: 0.6855 - accuracy: 0.5982\n",
            "Epoch 91/150\n",
            "112/112 [==============================] - 0s 748us/step - loss: 0.6798 - accuracy: 0.5893\n",
            "Epoch 92/150\n",
            "112/112 [==============================] - 0s 774us/step - loss: 0.6774 - accuracy: 0.5893\n",
            "Epoch 93/150\n",
            "112/112 [==============================] - 0s 785us/step - loss: 0.6764 - accuracy: 0.5982\n",
            "Epoch 94/150\n",
            "112/112 [==============================] - 0s 966us/step - loss: 0.6794 - accuracy: 0.5982\n",
            "Epoch 95/150\n",
            "112/112 [==============================] - 0s 717us/step - loss: 0.6865 - accuracy: 0.6071\n",
            "Epoch 96/150\n",
            "112/112 [==============================] - 0s 779us/step - loss: 0.6767 - accuracy: 0.5982\n",
            "Epoch 97/150\n",
            "112/112 [==============================] - 0s 724us/step - loss: 0.6816 - accuracy: 0.5982\n",
            "Epoch 98/150\n",
            "112/112 [==============================] - 0s 708us/step - loss: 0.6894 - accuracy: 0.5893\n",
            "Epoch 99/150\n",
            "112/112 [==============================] - 0s 698us/step - loss: 0.6849 - accuracy: 0.5982\n",
            "Epoch 100/150\n",
            "112/112 [==============================] - 0s 709us/step - loss: 0.6750 - accuracy: 0.5982\n",
            "Epoch 101/150\n",
            "112/112 [==============================] - 0s 784us/step - loss: 0.6728 - accuracy: 0.5982\n",
            "Epoch 102/150\n",
            "112/112 [==============================] - 0s 715us/step - loss: 0.6706 - accuracy: 0.5982\n",
            "Epoch 103/150\n",
            "112/112 [==============================] - 0s 705us/step - loss: 0.6792 - accuracy: 0.5982\n",
            "Epoch 104/150\n",
            "112/112 [==============================] - 0s 698us/step - loss: 0.6735 - accuracy: 0.5982\n",
            "Epoch 105/150\n",
            "112/112 [==============================] - 0s 765us/step - loss: 0.6842 - accuracy: 0.5982\n",
            "Epoch 106/150\n",
            "112/112 [==============================] - 0s 821us/step - loss: 0.6793 - accuracy: 0.5893\n",
            "Epoch 107/150\n",
            "112/112 [==============================] - 0s 729us/step - loss: 0.6910 - accuracy: 0.5893\n",
            "Epoch 108/150\n",
            "112/112 [==============================] - 0s 736us/step - loss: 0.6740 - accuracy: 0.5982\n",
            "Epoch 109/150\n",
            "112/112 [==============================] - 0s 735us/step - loss: 0.6871 - accuracy: 0.5982\n",
            "Epoch 110/150\n",
            "112/112 [==============================] - 0s 718us/step - loss: 0.6788 - accuracy: 0.5982\n",
            "Epoch 111/150\n",
            "112/112 [==============================] - 0s 719us/step - loss: 0.6836 - accuracy: 0.5893\n",
            "Epoch 112/150\n",
            "112/112 [==============================] - 0s 715us/step - loss: 0.6782 - accuracy: 0.5982\n",
            "Epoch 113/150\n",
            "112/112 [==============================] - 0s 707us/step - loss: 0.6647 - accuracy: 0.5982\n",
            "Epoch 114/150\n",
            "112/112 [==============================] - 0s 686us/step - loss: 0.6783 - accuracy: 0.5982\n",
            "Epoch 115/150\n",
            "112/112 [==============================] - 0s 700us/step - loss: 0.6703 - accuracy: 0.6071\n",
            "Epoch 116/150\n",
            "112/112 [==============================] - 0s 782us/step - loss: 0.6902 - accuracy: 0.5804\n",
            "Epoch 117/150\n",
            "112/112 [==============================] - 0s 768us/step - loss: 0.6764 - accuracy: 0.5982\n",
            "Epoch 118/150\n",
            "112/112 [==============================] - 0s 737us/step - loss: 0.6677 - accuracy: 0.5982\n",
            "Epoch 119/150\n",
            "112/112 [==============================] - 0s 718us/step - loss: 0.6802 - accuracy: 0.5893\n",
            "Epoch 120/150\n",
            "112/112 [==============================] - 0s 710us/step - loss: 0.6768 - accuracy: 0.6161\n",
            "Epoch 121/150\n",
            "112/112 [==============================] - 0s 712us/step - loss: 0.6660 - accuracy: 0.5982\n",
            "Epoch 122/150\n",
            "112/112 [==============================] - 0s 707us/step - loss: 0.6730 - accuracy: 0.5982\n",
            "Epoch 123/150\n",
            "112/112 [==============================] - 0s 829us/step - loss: 0.6514 - accuracy: 0.5982\n",
            "Epoch 124/150\n",
            "112/112 [==============================] - 0s 718us/step - loss: 0.6880 - accuracy: 0.5982\n",
            "Epoch 125/150\n",
            "112/112 [==============================] - 0s 734us/step - loss: 0.6737 - accuracy: 0.5893\n",
            "Epoch 126/150\n",
            "112/112 [==============================] - 0s 797us/step - loss: 0.6626 - accuracy: 0.6071\n",
            "Epoch 127/150\n",
            "112/112 [==============================] - 0s 714us/step - loss: 0.6568 - accuracy: 0.5982\n",
            "Epoch 128/150\n",
            "112/112 [==============================] - 0s 749us/step - loss: 0.6705 - accuracy: 0.6161\n",
            "Epoch 129/150\n",
            "112/112 [==============================] - 0s 775us/step - loss: 0.6546 - accuracy: 0.5982\n",
            "Epoch 130/150\n",
            "112/112 [==============================] - 0s 711us/step - loss: 0.6618 - accuracy: 0.5982\n",
            "Epoch 131/150\n",
            "112/112 [==============================] - 0s 714us/step - loss: 0.6606 - accuracy: 0.5982\n",
            "Epoch 132/150\n",
            "112/112 [==============================] - 0s 727us/step - loss: 0.6639 - accuracy: 0.5982\n",
            "Epoch 133/150\n",
            "112/112 [==============================] - 0s 737us/step - loss: 0.6472 - accuracy: 0.6071\n",
            "Epoch 134/150\n",
            "112/112 [==============================] - 0s 720us/step - loss: 0.6464 - accuracy: 0.5982\n",
            "Epoch 135/150\n",
            "112/112 [==============================] - 0s 757us/step - loss: 0.6340 - accuracy: 0.6071\n",
            "Epoch 136/150\n",
            "112/112 [==============================] - 0s 720us/step - loss: 0.6290 - accuracy: 0.6071\n",
            "Epoch 137/150\n",
            "112/112 [==============================] - 0s 699us/step - loss: 0.6194 - accuracy: 0.5982\n",
            "Epoch 138/150\n",
            "112/112 [==============================] - 0s 764us/step - loss: 0.6103 - accuracy: 0.6250\n",
            "Epoch 139/150\n",
            "112/112 [==============================] - 0s 747us/step - loss: 0.6094 - accuracy: 0.6518\n",
            "Epoch 140/150\n",
            "112/112 [==============================] - 0s 783us/step - loss: 0.5995 - accuracy: 0.6696\n",
            "Epoch 141/150\n",
            "112/112 [==============================] - 0s 868us/step - loss: 0.5705 - accuracy: 0.6786\n",
            "Epoch 142/150\n",
            "112/112 [==============================] - 0s 802us/step - loss: 0.5571 - accuracy: 0.7232\n",
            "Epoch 143/150\n",
            "112/112 [==============================] - 0s 791us/step - loss: 0.5593 - accuracy: 0.7500\n",
            "Epoch 144/150\n",
            "112/112 [==============================] - 0s 800us/step - loss: 0.5207 - accuracy: 0.7946\n",
            "Epoch 145/150\n",
            "112/112 [==============================] - 0s 822us/step - loss: 0.5176 - accuracy: 0.7679\n",
            "Epoch 146/150\n",
            "112/112 [==============================] - 0s 742us/step - loss: 0.4851 - accuracy: 0.8125\n",
            "Epoch 147/150\n",
            "112/112 [==============================] - 0s 747us/step - loss: 0.4853 - accuracy: 0.8482\n",
            "Epoch 148/150\n",
            "112/112 [==============================] - 0s 710us/step - loss: 0.4929 - accuracy: 0.8571\n",
            "Epoch 149/150\n",
            "112/112 [==============================] - 0s 783us/step - loss: 0.4802 - accuracy: 0.8750\n",
            "Epoch 150/150\n",
            "112/112 [==============================] - 0s 758us/step - loss: 0.4165 - accuracy: 0.9196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK1COdF1W_Wi",
        "colab_type": "text"
      },
      "source": [
        "## 7) Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHOIWFdhUuAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelname = 'QA_model.h5'\n",
        "model.save(modelname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRdSBciCXY7B",
        "colab_type": "text"
      },
      "source": [
        "## 8) Plotting the graph of training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQJqqK0GXQx4",
        "colab_type": "code",
        "outputId": "c5f2f74b-4309-4b49-bd15-acd639bb6b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkNoTYt_X9oK",
        "colab_type": "text"
      },
      "source": [
        "## 9) Prediction on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOz-aXe1XiTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(modelname)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A21gS5jSZMBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68a86b94-8312-463e-e313-a9cb70eb04c5"
      },
      "source": [
        "len(pred_results)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVUHZZIcYMeu",
        "colab_type": "code",
        "outputId": "ad3772b8-b062-45ac-e011-85aebb27bc41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(test_data[0][0])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i put out my hand and felt the meat chopper hanging to the wall . in a flash i was after him . i was fierce with fear . before he was halfway across the kitchen i had overtaken him . with one last touch of humanity i turned the blade back and struck the curate with the meat chopper . curate went headlong forward and lay stretched on the ground . i stumbled over curate and stood panting . he lay still .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-e_pa-AYP1g",
        "colab_type": "code",
        "outputId": "7ffcaa52-7122-4796-c0ae-8f97f01709c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_data[0][1]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['did', 'curate', 'went', 'headlong', 'forward', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpfWL2FpYYyS",
        "colab_type": "code",
        "outputId": "f064b381-b1ed-42ad-fb85-1f3899e64460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_data[0][2]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-xR1jY-YpVD",
        "colab_type": "code",
        "outputId": "ea65f8be-a119-4e1e-c337-b20af5693860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pred_results[0]   # Probability of occurence of each word from vocab in the answer."
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.33856361e-07, 1.04094944e-07, 9.58991322e-08, ...,\n",
              "       1.23092661e-07, 1.13178956e-07, 1.32650385e-07], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj_whrg2YjoS",
        "colab_type": "code",
        "outputId": "40d8891a-1a78-4b33-c6e7-ae674cf388d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Generating prediction from model\n",
        "\n",
        "val_max = np.argmax(pred_results[0])\n",
        "val_max"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro5MXlYBYbPU",
        "colab_type": "code",
        "outputId": "c44322cb-1205-4717-da44-15796dbd3ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.6539801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFn0Lv2yZqba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2c28029a-5cde-44d6-a81d-b49a22adf199"
      },
      "source": [
        "for res in pred_results:\n",
        "  print(res)\n",
        "  break"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.33856361e-07 1.04094944e-07 9.58991322e-08 ... 1.23092661e-07\n",
            " 1.13178956e-07 1.32650385e-07]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYFdvAXodffI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actual_results = ['yes','yes','no','yes','no','yes','no','yes','no','no','yes','yes',]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nfqM9UBZPhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking for all the test data set\n",
        "ans = []\n",
        "for result in pred_results:\n",
        "\n",
        "  val_max = np.argmax(result)\n",
        "\n",
        "  for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "  ans.append(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VH9r9-Hdxra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd9c003a-10d5-4569-e1a1-97ad1cb8bd16"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(ans,actual_results)*100\n",
        "accuracy = float(\"{:.2f}\".format(accuracy))\n",
        "print(f'Accuracy: {accuracy}%')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 91.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUDELjLx4YP2",
        "colab_type": "text"
      },
      "source": [
        "# <CENTER> THE END"
      ]
    }
  ]
}